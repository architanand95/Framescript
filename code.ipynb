{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1224 validated image filenames.\n",
      "Found 816 validated image filenames.\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 556s 14s/step - loss: 0.0575 - val_loss: 0.0410\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 380s 10s/step - loss: 0.0394 - val_loss: 0.0380\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 334s 8s/step - loss: 0.0363 - val_loss: 0.0375\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 301s 8s/step - loss: 0.0345 - val_loss: 0.0356\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 298s 8s/step - loss: 0.0331 - val_loss: 0.0349\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 298s 8s/step - loss: 0.0317 - val_loss: 0.0343\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 293s 8s/step - loss: 0.0309 - val_loss: 0.0346\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 282s 7s/step - loss: 0.0299 - val_loss: 0.0336\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 307s 8s/step - loss: 0.0289 - val_loss: 0.0335\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 337s 9s/step - loss: 0.0284 - val_loss: 0.0334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd  # Import pandas for DataFrame operations\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define paths to your image and text data directories\n",
    "image_dir = \"dataset2\"\n",
    "\n",
    "# Function to get filenames within a directory\n",
    "def get_files_in_directory(directory):\n",
    "    return [os.path.join(directory, file) for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n",
    "\n",
    "# Create lists to store selected filenames\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "# Iterate through subdirectories\n",
    "for subdir in os.listdir(image_dir):\n",
    "    subdir_path = os.path.join(image_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Get all image files in the subdirectory\n",
    "        files = get_files_in_directory(subdir_path)\n",
    "        # Sort files\n",
    "        files.sort()\n",
    "        # Select 5 files from serial number 55 to 60\n",
    "        selected_files = files[55:60]\n",
    "        # Split selected files for training and validation\n",
    "        random.shuffle(selected_files)\n",
    "        train_files.extend(selected_files[:3])  # Select 3 for training\n",
    "        val_files.extend(selected_files[3:])   # Select 2 for validation\n",
    "\n",
    "# Create an ImageDataGenerator for efficient image loading and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Splitting data into train and validation\n",
    ")\n",
    "\n",
    "# Load images using the ImageDataGenerator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.DataFrame(train_files, columns=[\"filename\"]),\n",
    "    directory=None,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"filename\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='input',  # Return images as both input and target\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.DataFrame(val_files, columns=[\"filename\"]),\n",
    "    directory=None,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"filename\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='input',  # Return images as both input and target\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Load the pre-trained ResNet50V2 model\n",
    "resnet50v2_model = ResNet50V2(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Create a custom model by freezing all layers except the top 2\n",
    "x = resnet50v2_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "output_layer = tf.keras.layers.Dense(224 * 224 * 3, activation=\"sigmoid\")(x)  # Output layer for the same size as input\n",
    "\n",
    "# Reshape the output to match the input shape\n",
    "output_layer = tf.keras.layers.Reshape((224, 224, 3))(output_layer)\n",
    "\n",
    "# Create the final model by adding the top layers to the pre-trained model\n",
    "custom_model = Model(inputs=resnet50v2_model.input, outputs=output_layer)\n",
    "\n",
    "# Freeze all layers except the top layers\n",
    "for layer in resnet50v2_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the custom model with appropriate optimizer and loss function\n",
    "custom_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the custom model\n",
    "history = custom_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Save the feature extraction model\n",
    "custom_model.save('feature_extraction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 160s 4s/step\n",
      "26/26 [==============================] - 107s 4s/step\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 6s 36ms/step - loss: 1.1125 - val_loss: 1.0999\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0920 - val_loss: 1.0991\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0776 - val_loss: 1.1023\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0580 - val_loss: 1.1057\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0350 - val_loss: 1.1138\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.0011 - val_loss: 1.1353\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.9688 - val_loss: 1.1385\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.9357 - val_loss: 1.1401\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.8948 - val_loss: 1.2147\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.8405 - val_loss: 1.2618\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths to your image and text data directories\n",
    "dataset_dir = \"dataset1\"\n",
    "\n",
    "# Function to get subdirectories within a directory\n",
    "def get_subdirectories(directory):\n",
    "    return [os.path.join(directory, subdir) for subdir in os.listdir(directory) if os.path.isdir(os.path.join(directory, subdir))]\n",
    "\n",
    "# Create lists to store selected filenames\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "# Iterate through subdirectories\n",
    "subdirs = get_subdirectories(dataset_dir)\n",
    "for subdir in subdirs:\n",
    "    # Get all image files in the subdirectory\n",
    "    files = [os.path.join(subdir, file) for file in os.listdir(subdir) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    # Sort files\n",
    "    files.sort()\n",
    "    # Select 5 files\n",
    "    selected_files = files[:5]\n",
    "    # Split selected files for training and validation\n",
    "    random.shuffle(selected_files)\n",
    "    train_files.extend(selected_files[:3])  # Select 3 for training\n",
    "    val_files.extend(selected_files[3:])   # Select 2 for validation\n",
    "\n",
    "# Define a function to load and preprocess images\n",
    "def load_image(file_path):\n",
    "    img = load_img(file_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Load images and preprocess them\n",
    "train_images = np.array([load_image(img_path) for img_path in train_files])\n",
    "val_images = np.array([load_image(img_path) for img_path in val_files])\n",
    "\n",
    "# Load the pre-trained ResNet50V2 model\n",
    "resnet50v2_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Create a custom model on top of ResNet50V2 for image feature extraction\n",
    "x = resnet50v2_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "image_features = tf.keras.layers.Dense(128, activation='relu')(x)  # Image features of size 128\n",
    "\n",
    "# Define inputs for the model\n",
    "image_input = resnet50v2_model.input\n",
    "\n",
    "# Create a model that outputs image features\n",
    "image_model = Model(inputs=image_input, outputs=image_features)\n",
    "\n",
    "# Compile the image model\n",
    "image_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Get image features for training and validation images\n",
    "train_image_features = image_model.predict(train_images)\n",
    "val_image_features = image_model.predict(val_images)\n",
    "\n",
    "# Define a simple model for understanding relationships between images\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128,)),  # Image features size\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Output for 3 classes (example)\n",
    "])\n",
    "\n",
    "# Compile the model with appropriate optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Define labels (example: 0, 1, 2 for different relationships)\n",
    "labels = np.array([0, 1, 2] * (len(train_files) // 3))\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_image_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Save the trained image model and relationship model\n",
    "image_model.save('image_model.h5')\n",
    "model.save('relationship_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 115ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=100) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=100) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=100) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=100) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=100) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=100) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Story:\n",
      "Beginning:\n",
      "Beginning: \n",
      "    This is a sample script. You can replace this with your actual script.\n",
      "    \n",
      ", the the, the, the the the. the the rise and the the. in., of, to and. the the the,. in the. the and.Settings,,, the the the and the to the to▬,▬ and the of the the in the the the,, the the of the rise the the the the the in the the in in, the the warrant the the of the the the the, Beef the the the the the the. the, the\n",
      "Beginning: \n",
      "    This is a sample script. You can replace this with your actual script.\n",
      "    \n",
      ", the the, the, the the the. the the rise and the the. in., of, to and. the the the,. in the. the and.Settings,,, the the the and the to the to▬,▬ and the of the the in the the the,, the the of the rise the the the the the in the the in in, the the warrant the the of the the the the, Beef the the the the the the. the, the\n",
      " the and and the the the. the the the the the the the to, the the, the to to the the the, the the, the the. in the the,. the, the to the,, the Orleans, physiological.. the theSettings, the Beef, the of the the,, and the the the Cartoon the the the to the the to, and. and the, the the the▬ define, the the the,▬, and quar there, the the\n",
      "\n",
      "\n",
      "Beginning:\n",
      "Beginning: \n",
      "    This is a sample script. You can replace this with your actual script.\n",
      "    \n",
      "- the to and andstrong Cor,- in the, theTel., the the rise the the the the the the,. thecharg the the the. and the, the the in and,, and the the the Beef of the and and and, the the,.. the the the the▬ the to, and to the the Lizard, the and the,,,,, the, the▬ Shan of the the the, to and and the the.,..,\n",
      "Beginning: \n",
      "    This is a sample script. You can replace this with your actual script.\n",
      "    \n",
      "- the to and andstrong Cor,- in the, theTel., the the rise the the the the the the,. thecharg the the the. and the, the the in and,, and the the the Beef of the and and and, the the,.. the the the the▬ the to, and to the the Lizard, the and the,,,,, the, the▬ Shan of the the the, to and and the the.,..,\n",
      ", to the to the and,, the, of the the and and the the,, and the the dismissed,Settings, the, and the, of the, the the., the, the., the, and the, the the the the the for. arsenic Shan the the and to,, the.. the of the the the the the the the the the the the the., and the the the. a, the the. the the the the.,,,\n",
      "\n",
      "\n",
      "Middle:\n",
      "Middle: \n",
      "    This is a sample script. You can replace this with your actual script.\n",
      "    \n",
      ",, the the and rise. and the in the and, the, the the to and the and are, the the the the the the to the the.., the,, the,, and and the, to the to the the to the the the., the the the. to the and the the the the the to the the to the to the the the of the the the the to, the the the the the and the, frames. the the the the the\n",
      "Middle: \n",
      "    This is a sample script. You can replace this with your actual script.\n",
      "    \n",
      ",, the the and rise. and the in the and, the, the the to and the and are, the the the the the the to the the.., the,, the,, and and the, to the to the the to the the the., the the the. to the and the the the the the to the the to the to the the the of the the the the to, the the the the the and the, frames. the the the the the\n",
      ", the, and in the the, of the the the the. the the. the the the to and the, the the the the, the the the the to the the the the the in the,. and the the the.. the the rise the and the the. in the the, the the to of the to the and the▬. theTar the, the,, the the the the to,, the the the the the the to the inpaced the the the the\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the pre-trained ResNet50V2 model with modified output shape\n",
    "resnet50v2_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, pooling='avg')\n",
    "resnet50v2_model_output = resnet50v2_model.output\n",
    "resnet50v2_model_output = tf.keras.layers.Dense(128, activation='relu')(resnet50v2_model_output)\n",
    "resnet50v2_model = tf.keras.Model(inputs=resnet50v2_model.input, outputs=resnet50v2_model_output)\n",
    "\n",
    "# Load the trained relationship model\n",
    "relationship_model = tf.keras.models.load_model('relationship_model.h5')\n",
    "\n",
    "# Define the local directory containing GPT-2 model files\n",
    "gpt2_dir = \"gpt2-small\"\n",
    "\n",
    "# Manually load GPT-2 tokenizer with pad_token as '<pad>'\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(gpt2_dir, pad_token='<pad>')\n",
    "\n",
    "# Manually load GPT-2 model\n",
    "model_gpt2 = GPT2LMHeadModel.from_pretrained(gpt2_dir)\n",
    "\n",
    "# Define the image directory and example image paths\n",
    "image_dir = \"dataset1\"\n",
    "image_paths = [\"1.png\", \"2.png\", \"3.png\"]  # Example image paths\n",
    "\n",
    "# Define a function to extract image features using ResNet50V2\n",
    "def extract_image_features(image_paths):\n",
    "    images = [load_img(os.path.join(image_dir, img_path), target_size=(224, 224)) for img_path in image_paths]\n",
    "    images = np.array([img_to_array(img) for img in images])\n",
    "    images = tf.keras.applications.resnet50.preprocess_input(images)\n",
    "    features = resnet50v2_model.predict(images)\n",
    "    return features\n",
    "\n",
    "# Define a function to predict relationships using the relationship model\n",
    "def predict_relationship(image_features):\n",
    "    predictions = relationship_model.predict(image_features)\n",
    "    return predictions\n",
    "\n",
    "# Define a function to generate text with GPT-2 in chunks\n",
    "def generate_text(relationship, script):\n",
    "    # Combine the input prompt with the script\n",
    "    input_text = f\"{relationship}: {script}\\n\"\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer_gpt2.encode(input_text, return_tensors='pt')\n",
    "    \n",
    "    # Ensure input_ids is within range of model's vocabulary\n",
    "    input_ids = input_ids[:, :model_gpt2.config.max_position_embeddings]\n",
    "    \n",
    "    # Clip input_ids to the maximum vocabulary size\n",
    "    input_ids = input_ids.clip(0, model_gpt2.config.vocab_size - 1)\n",
    "    \n",
    "    # Initialize generated text\n",
    "    generated_text = \"\"\n",
    "    \n",
    "    # Generate text in chunks\n",
    "    while len(generated_text) < 1000:\n",
    "        with torch.no_grad():\n",
    "            output = model_gpt2.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=200,  # Set a smaller max_length for chunks\n",
    "                pad_token_id=tokenizer_gpt2.eos_token_id,\n",
    "                do_sample=True,\n",
    "                top_p=0.95,\n",
    "                top_k=50,\n",
    "                max_new_tokens=100  # Limit the new tokens added\n",
    "            )\n",
    "        \n",
    "        # Decode the generated text for this chunk\n",
    "        chunk_text = tokenizer_gpt2.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Add the chunk to the generated text\n",
    "        generated_text += chunk_text + \"\\n\"\n",
    "        \n",
    "        # Update input_ids for the next chunk\n",
    "        input_ids = tokenizer_gpt2.encode(generated_text, return_tensors='pt')\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# Define a function to generate the story\n",
    "def generate_story(image_paths):\n",
    "    # Extract image features\n",
    "    image_features = extract_image_features(image_paths)\n",
    "    \n",
    "    # Predict relationships\n",
    "    relationship_predictions = predict_relationship(image_features)\n",
    "    \n",
    "    # Define the relationships\n",
    "    relationships = [\"Beginning\", \"Middle\", \"End\"]\n",
    "    \n",
    "    # Load script sample from textdir.xlsx (assuming you have this file)\n",
    "    script_sample = \"\"\"\n",
    "    This is a sample script. You can replace this with your actual script.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate story\n",
    "    story = \"\"\n",
    "    for i, relationship_prob in enumerate(relationship_predictions):\n",
    "        relationship_idx = np.argmax(relationship_prob)\n",
    "        selected_relationship = relationships[relationship_idx]\n",
    "        generated_text = generate_text(selected_relationship, script_sample)\n",
    "        story += f\"{selected_relationship}:\\n{generated_text}\\n\\n\"\n",
    "    \n",
    "    return story\n",
    "\n",
    "# Generate story for the given image paths\n",
    "generated_story = generate_story(image_paths)\n",
    "\n",
    "print(\"Generated Story:\")\n",
    "print(generated_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Story:\n",
      "Beginning:\n",
      "Image: dataset1\\1.png\n",
      "Script: Beginning: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "Middle:\n",
      "Image: dataset1\\1.png\n",
      "Script: Middle: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "The script is a simple script that will create a new folder called \"data1\" and then create a new folder called \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the\n",
      "\n",
      "\n",
      "End:\n",
      "Image: dataset1\\1.png\n",
      "Script: End: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "The script is a simple script that will create a new file called \"data1.txt\" and then create a new file called \"data2.txt\" and then create a new file called \"data3.txt\" and then create a new file called \"data4.txt\" and then create a new file called \"data5.txt\" and then create a new file called \"data6.txt\" and then create a new file called \"data7.txt\" and then create a new file called \"data8.txt\" and then create a new file called \"data9.txt\" and then create a new file called \"data10.txt\" and then create a new file called \"data11.txt\" and then create a new file called \"data12.txt\" and then create a new file called \"data13.txt\" and then create a new file called \"data14.txt\" and then create a new file called \"data15.txt\" and then create a new file called \"data16.txt\" and then create a new file called \"data17.txt\" and then create a new file called \"data18.txt\" and then create a new file called \"data19.txt\" and then create a new file called \"data20.txt\" and then\n",
      "\n",
      "\n",
      "Beginning:\n",
      "Image: dataset1\\2.png\n",
      "Script: Beginning: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "Middle:\n",
      "Image: dataset1\\2.png\n",
      "Script: Middle: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "The script is a simple script that will create a new folder called \"data1\" and then create a new folder called \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the\n",
      "\n",
      "\n",
      "End:\n",
      "Image: dataset1\\2.png\n",
      "Script: End: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "The script is a simple script that will create a new file called \"data1.txt\" and then create a new file called \"data2.txt\" and then create a new file called \"data3.txt\" and then create a new file called \"data4.txt\" and then create a new file called \"data5.txt\" and then create a new file called \"data6.txt\" and then create a new file called \"data7.txt\" and then create a new file called \"data8.txt\" and then create a new file called \"data9.txt\" and then create a new file called \"data10.txt\" and then create a new file called \"data11.txt\" and then create a new file called \"data12.txt\" and then create a new file called \"data13.txt\" and then create a new file called \"data14.txt\" and then create a new file called \"data15.txt\" and then create a new file called \"data16.txt\" and then create a new file called \"data17.txt\" and then create a new file called \"data18.txt\" and then create a new file called \"data19.txt\" and then create a new file called \"data20.txt\" and then\n",
      "\n",
      "\n",
      "Beginning:\n",
      "Image: dataset1\\3.png\n",
      "Script: Beginning: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "Script: Beginning: \n",
      "\n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "This script is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "Middle:\n",
      "Image: dataset1\\3.png\n",
      "Script: Middle: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "The script is a simple script that will create a new folder called \"data1\" and then create a new folder called \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the folder name is \"data2\".\n",
      "\n",
      "The folder name is \"data1\" and the\n",
      "\n",
      "\n",
      "End:\n",
      "Image: dataset1\\3.png\n",
      "Script: End: \n",
      "This is a sample script. You can replace this with your actual script.\n",
      "\n",
      "\n",
      "The script is a simple script that will create a new file called \"data.csv\" and then create a new file called \"data.txt\".\n",
      "\n",
      "The file is named \"data.csv\" and it contains the following:\n",
      "\n",
      "data.csv\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "data.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Example image paths\n",
    "image_dir = \"dataset1\"\n",
    "image_paths = [os.path.join(image_dir, \"1.png\"), os.path.join(image_dir, \"2.png\"), os.path.join(image_dir, \"3.png\")]\n",
    "\n",
    "# Example script\n",
    "script_sample = \"\"\"\n",
    "This is a sample script. You can replace this with your actual script.\n",
    "\"\"\"\n",
    "\n",
    "# Define the relationships\n",
    "relationships = [\"Beginning\", \"Middle\", \"End\"]\n",
    "\n",
    "# Load the GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "def generate_story(image_path, script_sample):\n",
    "    # Combine the image path and script into a prompt\n",
    "    prompt = f\"Image: {image_path}\\nScript: {script_sample}\\n\"\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Generate the story using GPT-2\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=300, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text.strip()\n",
    "\n",
    "# Generate stories for all images\n",
    "generated_stories = []\n",
    "for image_path in image_paths:\n",
    "    for relationship in relationships:\n",
    "        generated_story = generate_story(image_path, f\"{relationship}: {script_sample}\")\n",
    "        generated_stories.append(f\"{relationship}:\\n{generated_story}\\n\\n\")\n",
    "\n",
    "# Combine all stories into a single narrative\n",
    "final_story = \"\\n\".join(generated_stories)\n",
    "\n",
    "# Print the final generated story\n",
    "print(\"Generated Story:\")\n",
    "print(final_story)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
